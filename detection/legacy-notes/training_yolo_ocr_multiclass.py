# -*- coding: utf-8 -*-
"""TRAINING_yolo_ocr_multiclass.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11khb734CA2ZOsXw69QiDomVa3W041SXR

# Modern Approach: YOLOv8 OCR Detection for Container Codes

# This notebook uses a YOLOv8 model to directly find AND recognise the 11 characters on a shipping container.

### 1. Setup

# First, ensure your environment and data are set up correctly.

**Project Structure:**
Your data should be in the following structure, inside the `data/` directory:
```
dataset/
├── container_dataset.yaml
├── images/
│   ├── train/
│   └── val/
└── labels/
    ├── train/
    └── val/
```

**Annotations:**
- Place your training images and labels in `data/dataset/images/train` and `data/dataset/labels/train`.
- Place your validation images and labels in `data/dataset/images/val` and `data/dataset/labels/val`.
- The `container_dataset.yaml` file should point to these directories and define the single 'character' class.
"""

# Commented out IPython magic to ensure Python compatibility.
# Install the Ultralytics library, which contains YOLOv8
# %pip install ultralytics

from ultralytics import YOLO
import torch
from pathlib import Path
import matplotlib.pyplot as plt

pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="")                # your key

ws = rf.workspace("cargosnap")       # make sure this slug matches the URL

print("Projects in workspace:")
for slug in ws.projects():           # returns strings
    print("  •", slug)

# Access the workspace and project
project = rf.workspace("cargosnap").project("container-character-ocr")

# Get version 1 and download the dataset in YOLO format (or other, see below)
dataset = project.version(1).download("yolov8")  # or "yolov8", "coco", etc.

"""# ### 2. Train the Model

# Now we'll train the YOLOv8 model. We use `yolov8n.pt`, the smallest and fastest version, as a starting point (pre-trained weights). The model will learn from our custom container dataset.

"""

# Commented out IPython magic to ensure Python compatibility.
# Load a pre-trained YOLOv8n model
model = YOLO("yolov8n.pt")

# Train the model
# Note: The first time you run this, it will download the yolov8n.pt weights.
results = model.train(
    data="Container-Character-OCR-1/data.yaml",
    epochs=150,  # As per the plan, start with 50 and increase if needed
    imgsz=640,  # Standard input size for YOLO
    device="cuda",
    project="runs/detect",
    name="container_exp"  # Name for the experiment directory
)

# %load_ext tensorboard
# %tensorboard --logdir runs/detect

from ultralytics import YOLO

# Load best weights
model = YOLO("runs/detect/container_exp2/weights/best.pt")

# Run evaluation on test set (ensure YAML defines 'test' section properly)
results = model.val(data="Container-Character-OCR-1/data.yaml", split="test")

# Extract and print mAP results
print("mAP@0.5:", results.results_dict.get("metrics/mAP50(B)", "N/A"))
print("mAP@0.5:0.95:", results.results_dict.get("metrics/mAP50-95(B)", "N/A"))

results.plot_confusion_matrix(normalize=True, save_dir="conf_matrix")

from ultralytics import YOLO
model = YOLO("runs/detect/container_exp2/weights/best.pt")

# TFLite INT8 (Android)
model.export(format="tflite", int8=True)      # → best_int8.tflite

# Core ML FP16 (iOS)
model.export(format="coreml", half=True)      # → best_fp16.mlmodel

# ONNX FP16 (cross-platform)
model.export(format="onnx", half=True)        # → best_fp16.onnx

from google.colab import files   # already available in Colab

# pick the ones you need
files.download('runs/detect/container_exp2/weights/best_saved_model/best_int8.tflite')
files.download('runs/detect/container_exp2/weights/best.mlpackage')
files.download('runs/detect/container_exp2/weights/best.onnx')

# not used (but pretty good:)

import os
import logging
from pathlib import Path
from ultralytics import YOLO

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("training.log")
    ]
)
logger = logging.getLogger(__name__)

def train_model(
    data_yaml: str = "YOLO-OCR/container_dataset.yaml",
    epochs: int = 150,
    batch_size: int = 16,
    img_size: int = 640,
    device: str = "cuda"
) -> None:
    """
    Train a YOLOv8 model on the annotated dataset.

    Args:
        data_yaml: Path to the dataset configuration file
        epochs: Number of training epochs
        batch_size: Batch size for training
        img_size: Input image size
        device: Device to use for training ('cpu' for CPU training)
    """
    try:
        # Initialize model
        logger.info("Initializing YOLOv8 model...")
        model = YOLO("yolov8n.pt")  # Load the smallest YOLOv8 model

        # Create results directory
        results_dir = Path("results")
        results_dir.mkdir(exist_ok=True)

        # Training configuration
        logger.info("Starting training with configuration:")
        logger.info(f"- Epochs: {epochs}")
        logger.info(f"- Batch size: {batch_size}")
        logger.info(f"- Image size: {img_size}")
        logger.info(f"- Device: {device}")

        # Train the model
        results = model.train(
            data=data_yaml,
            epochs=epochs,
            batch=batch_size,
            imgsz=img_size,
            device=device,
            project="results",
            name="train",
            exist_ok=True,
            pretrained=True,
            optimizer="auto",
            verbose=True,
            seed=42,
            deterministic=True,
            plots=True,  # Generate training plots
            save=True,  # Save best model
            save_period=10,  # Save checkpoint every 10 epochs
        )

        logger.info("Training completed successfully!")
        logger.info(f"Results saved in: {results_dir / 'train'}")

        # Print final metrics
        metrics = results.results_dict
        logger.info("\nFinal metrics:")
        logger.info(f"mAP50: {metrics.get('metrics/mAP50(B)', 'N/A')}")
        logger.info(f"mAP50-95: {metrics.get('metrics/mAP50-95(B)', 'N/A')}")
        logger.info(f"Precision: {metrics.get('metrics/precision(B)', 'N/A')}")
        logger.info(f"Recall: {metrics.get('metrics/recall(B)', 'N/A')}")

    except Exception as e:
        logger.error(f"An error occurred during training: {str(e)}")
        raise

if __name__ == "__main__":
    train_model()

"""### 3. Evaluate and Run Inference

After training, the best model weights are automatically saved to `runs/detect/container_exp/weights/best.pt`. We can now use this custom-trained model to make predictions on new images that it has never seen before.

"""

# Load your custom-trained model from the saved weights
model_path = Path("/Users/marcelmerkx/Development/container-digit-detector/models/best-YOLO-10-06-25.pt")

if not model_path.exists():
    print(f"Model weights not found at {model_path}.")
    print("Please ensure the model has been trained successfully.")
else:
    model = YOLO(model_path)

    # --- IMPORTANT ---
    # Replace this with a path to a REAL image from your validation set.
    # For example: test_image_path = "data/dataset/images/val/your_image_name.jpg"
    test_image_path = "../data/dataset/images/val/ACLU9689902.jpg"

    if not Path(test_image_path).exists():
        print(f"Test image not found at {test_image_path}")
        print("Please update the `test_image_path` variable with a valid file path.")
    else:
        # Run inference on the test image
        inference_results = model(test_image_path)

        # The results object contains bounding boxes, confidence scores, and classes.
        # We can use the .plot() method to easily visualize the results.
        for r in inference_results:
            im_array = r.plot()  # This plots predictions on the image

            # Display the image with predictions using Matplotlib
            plt.figure(figsize=(12, 12))
            plt.imshow(im_array[..., ::-1])  # Convert BGR to RGB for correct color
            plt.title("Inference Result")
            plt.axis("off")
            plt.show()

print(os.path.exists("/Users/marcelmerkx/Development/container-digit-detector/models/best-YOLO-10-06-25.pt"))  # Should print True

from ultralytics import YOLO

model = YOLO("/Users/marcelmerkx/Development/container-digit-detector/models/best-YOLO-10-06-25.pt")
results = model.predict(
    source="../data/dataset/images/val/ACLU9689902.jpg",
    conf=0.1,         # set confidence threshold
    save=True,
)